---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

王雪莹 北京邮电大学 

Xueying Wang, Beijing University of Posts and Telecommunications, Posdoctor Researcher

# Brief Biography

My academic journey started with the guidance of the distinguished Xiaobing Feng, under whose mentorship I completed my doctorate degree at the Institute of Computing Technology, Chinese Academy of Sciences (ICT, CAS). My research interests are focused on parallel computing and compiler optimization for machine learning applications, including quantized Winograd convolution optimization(TACO,2024), hardware-aware NAS tuning (JSA, 2023), memory scheduling system(TACO,2023), and operator fusion(Euro-par, 2020). I am passionate about exploring how we can harness the power of parallel processing to solve complex computational problems and how compiler optimizations can further enhance the performance of these systems.

I am always open to collaboration and look forward to engaging with fellow researchers, and students. Thank you for visiting, and if you have any questions or wish to discuss potential research opportunities, please do not hesitate to contact me.


# Work  and Education Experience
* Postdoctor at School of Computer science, Beijing University of Posts and Telecommunications, 2023 - Now (Co-advisor: [Li Shigang](https://shigangli.github.io/) )
* Ph.D in Computer System Architecture, Institute of Computing Technology, Chinese Academy of Sciences, 2017 - 2023 (Advisor: [Feng Xiaobing](https://www.ict.ac.cn/sourcedb/cn/jssrck/200909/t20090917_2496613.html))
* B.S. in Software Engineering, Northeast Normal University, 2013 - 2017


# Representative Publications
* **[TACO'25, CCF-A]** OptiFX: Automatic Optimization for Convolutional Neural Networks with Aggressive Operator Fusion on GPUs. **Xueying Wang**, Shigang Li, Hao Qian, Fan Luo, Zhaoyang Hao, Tong Wu, Ruiyuan Xu, Huimin Cui, Xiaobing Feng, Guangli Li, Jingling Xue. ACM Transactions on Architecture and Code Optimization, 2025.

* **[TACO'24, CCF-A]** Fast convolution meets low precision: Exploring efficient quantized Winograd convolution on modern CPUs[J]. **Xueying Wang**, Guangli Li, Zhen Jia, Xiaobing Feng, Yida Wang. ACM Transactions on Architecture and Code Optimization, 2024.

* **[TACO'22, CCF-A]**An application-oblivious memory scheduling system for DNN accelerators[J]. Jiansong Li\*, **Xueying Wang\* **(Equal Contribution), Xiaobing Chen, Guangli Li, Xiao Dong, Peng Zhao, Xianzhi Yu, Yongxin Yang, Wei Cao, Lei Liu, Xiaobing Feng. ACM Transactions on Architecture and Code Optimization, 2022.

* **[JSA'23, CCF-B]** Facilitating hardware-aware neural architecture search with learning-based predictive models[J]. **Xueying Wang**, Guangli Li, Xiu Ma, Xiaobing Feng. Journal of Systems Architecture, 2023.

* **[JSA'23, CCF-B]** CoAxNN: Optimizing on-device deep learning with conditional approximate neural networks[J]. Guangli Li, Xiu Ma, Qiuchu Yu, Lei Liu, Huaxiao Liu, **Xueying Wang** (Corresponding author). Journal of Systems Architecture, 2023.

* **[EuroPar'20, CCF-B]** Accelerating deep learning inference with cross-layer data reuse on GPUs[C]. **Xueying Wang**, Guangli Li, Xiao Dong, Jiansong Li, Lei Liu, Xiaobing Feng. European Conference on Parallel Processing, 2020.



